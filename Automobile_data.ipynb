{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNf3bXhnarS0oBxJduKWDOI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/udbhavmishra/author/blob/master/Automobile_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HJBWNV2ukWOW",
        "outputId": "c26fdeeb-6551-40d5-83ad-378043fe4726"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pdfplumber pandas openpyxl"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bDFFZGY4kcuN",
        "outputId": "befb8940-f9e0-47b7-b448-84db1aaa9477"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pdfplumber\n",
            "  Downloading pdfplumber-0.11.2-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.0/58.0 kB\u001b[0m \u001b[31m833.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.0.3)\n",
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.10/dist-packages (3.1.5)\n",
            "Collecting pdfminer.six==20231228 (from pdfplumber)\n",
            "  Downloading pdfminer.six-20231228-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Pillow>=9.1 in /usr/local/lib/python3.10/dist-packages (from pdfplumber) (9.4.0)\n",
            "Collecting pypdfium2>=4.18.0 (from pdfplumber)\n",
            "  Downloading pypdfium2-4.30.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m28.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six==20231228->pdfplumber) (3.3.2)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six==20231228->pdfplumber) (42.0.8)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.25.2)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.10/dist-packages (from openpyxl) (1.1.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (1.16.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (2.22)\n",
            "Installing collected packages: pypdfium2, pdfminer.six, pdfplumber\n",
            "Successfully installed pdfminer.six-20231228 pdfplumber-0.11.2 pypdfium2-4.30.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import pdfplumber\n",
        "# import pandas as pd\n",
        "\n",
        "# # Open the PDF file\n",
        "# pdf_path = '/content/29999420 (6516327) Loss Run.pdf'\n",
        "# with pdfplumber.open(pdf_path) as pdf:\n",
        "#     pages = pdf.pages\n",
        "#     data = []\n",
        "#     for page in pages:\n",
        "#         table = page.extract_table()\n",
        "#         if table:\n",
        "#             data.extend(table)\n",
        "\n",
        "# # Convert to DataFrame and clean it up\n",
        "# df = pd.DataFrame(data[1:], columns=data[0])\n",
        "\n",
        "# # Remove blank columns\n",
        "# df = df.dropna(axis=1, how='all')\n",
        "\n",
        "# # # Save to Excel\n",
        "# # excel_path = '/content/drive/loss'\n",
        "# # df.to_excel(excel_path, index=False)\n",
        "# # excel_path\n"
      ],
      "metadata": {
        "id": "BVhDnCChkXTl"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# df"
      ],
      "metadata": {
        "id": "b9KcTFZukXKH"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# df1=df.to_excel('output.xlsx', index=False)\n",
        "# df1\n",
        "# #"
      ],
      "metadata": {
        "id": "ugJfwWWxkXCW"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# df1.head()"
      ],
      "metadata": {
        "id": "NkZsIw4bl0iv"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DvOw9P30l8BP"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "a6zJjeGTeV3V"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MLPSVXHweV0F"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pdfplumber\n",
        "import pandas as pd\n",
        "\n",
        "# Open the PDF file\n",
        "pdf_path = '/content/24-25 Submission (2).pdf'\n",
        "with pdfplumber.open(pdf_path) as pdf:\n",
        "    pages = pdf.pages\n",
        "    data = []\n",
        "    for page in pages:\n",
        "        table = page.extract_table()\n",
        "        if table:\n",
        "            data.extend(table)\n",
        "\n",
        "# Convert to DataFrame and clean it up\n",
        "df = pd.DataFrame(data[1:], columns=data[0])\n",
        "\n",
        "# Remove blank columns\n",
        "df = df.dropna(axis=1, how='all')\n",
        "\n",
        "# Save to Excel\n",
        "excel_path = '/content/sample_data.xlsx'\n",
        "df.to_excel(excel_path, index=False)\n",
        "excel_path\n"
      ],
      "metadata": {
        "id": "bkLRrbIyeVxl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "5214a632-6d27-4c26-9322-e95edc5e20a6"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/sample_data.xlsx'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        },
        "id": "UssWnL4DeVu1",
        "outputId": "310e0dd2-0ed0-465a-a2e8-4331a6e3dd49"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                # UNIT # SSOL ELBAYAP  YEAR  \\\n",
              "0                            None   None         None  None   \n",
              "1                            None   None         None  None   \n",
              "2  HEAVY COMMERCIAL - DUMP TRUCKS   None         None  None   \n",
              "3                               1    FL1               2004   \n",
              "4                               2    FL2               2006   \n",
              "\n",
              "                       MAKE/MODEL      SERIAL NUMBER    VALUE  \\\n",
              "0                            None               None     None   \n",
              "1                            None               None     None   \n",
              "2                            None               None     None   \n",
              "3  Freightliner FLD120SD T/A Dump  1FVHALAV04DN28068  $75,000   \n",
              "4         Freightliner Dump Truck  1FVHALAV56DW57006  $75,000   \n",
              "\n",
              "         SECTION A      SECTION A.1          SECTION B  \\\n",
              "0       $5,000,000  DCPD DEDUCTIBLE  ACCIDENT BENEFITS   \n",
              "1  LIABILITY LIMIT             None               None   \n",
              "2             None             None               None   \n",
              "3          Covered                             Covered   \n",
              "4          Covered                             Covered   \n",
              "\n",
              "  SECTION C - PHYSICAL DAMAGE                   None               None  \\\n",
              "0      ALL PERILS\\nDEDUCTIBLE  COLLISION\\nDEDUCTIBLE  COMP.\\nDEDUCTIBLE   \n",
              "1                        None                   None               None   \n",
              "2                        None                   None               None   \n",
              "3                      $5,000                                             \n",
              "4                      $5,000                                             \n",
              "\n",
              "                       None                ENDORSEMENTS ADD/\\nDELETE\\nDATE  \n",
              "0  SPEC. PERILS\\nDEDUCTIBLE                        None               None  \n",
              "1                      None                        None               None  \n",
              "2                      None                        None               None  \n",
              "3                            21B, 23A, 30, 30A,\\n40, 44                     \n",
              "4                            21B, 23A, 30, 30A,\\n40, 44                     "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f29a4ebd-3fe1-456e-8401-1e7913a7f292\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>#</th>\n",
              "      <th>UNIT #</th>\n",
              "      <th>SSOL ELBAYAP</th>\n",
              "      <th>YEAR</th>\n",
              "      <th>MAKE/MODEL</th>\n",
              "      <th>SERIAL NUMBER</th>\n",
              "      <th>VALUE</th>\n",
              "      <th>SECTION A</th>\n",
              "      <th>SECTION A.1</th>\n",
              "      <th>SECTION B</th>\n",
              "      <th>SECTION C - PHYSICAL DAMAGE</th>\n",
              "      <th>None</th>\n",
              "      <th>None</th>\n",
              "      <th>None</th>\n",
              "      <th>ENDORSEMENTS</th>\n",
              "      <th>ADD/\\nDELETE\\nDATE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>$5,000,000</td>\n",
              "      <td>DCPD DEDUCTIBLE</td>\n",
              "      <td>ACCIDENT BENEFITS</td>\n",
              "      <td>ALL PERILS\\nDEDUCTIBLE</td>\n",
              "      <td>COLLISION\\nDEDUCTIBLE</td>\n",
              "      <td>COMP.\\nDEDUCTIBLE</td>\n",
              "      <td>SPEC. PERILS\\nDEDUCTIBLE</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>LIABILITY LIMIT</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>HEAVY COMMERCIAL - DUMP TRUCKS</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>FL1</td>\n",
              "      <td></td>\n",
              "      <td>2004</td>\n",
              "      <td>Freightliner FLD120SD T/A Dump</td>\n",
              "      <td>1FVHALAV04DN28068</td>\n",
              "      <td>$75,000</td>\n",
              "      <td>Covered</td>\n",
              "      <td></td>\n",
              "      <td>Covered</td>\n",
              "      <td>$5,000</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>21B, 23A, 30, 30A,\\n40, 44</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2</td>\n",
              "      <td>FL2</td>\n",
              "      <td></td>\n",
              "      <td>2006</td>\n",
              "      <td>Freightliner Dump Truck</td>\n",
              "      <td>1FVHALAV56DW57006</td>\n",
              "      <td>$75,000</td>\n",
              "      <td>Covered</td>\n",
              "      <td></td>\n",
              "      <td>Covered</td>\n",
              "      <td>$5,000</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>21B, 23A, 30, 30A,\\n40, 44</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f29a4ebd-3fe1-456e-8401-1e7913a7f292')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f29a4ebd-3fe1-456e-8401-1e7913a7f292 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f29a4ebd-3fe1-456e-8401-1e7913a7f292');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-0a0cef1a-3065-4875-b897-65fc8a7e192a\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0a0cef1a-3065-4875-b897-65fc8a7e192a')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-0a0cef1a-3065-4875-b897-65fc8a7e192a button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 173,\n  \"fields\": [\n    {\n      \"column\": \"#\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 73,\n        \"samples\": [\n          \"4\",\n          \"Heavy Commercial Drill Trucks\",\n          \"HEAVY COMMERCIAL - WATER TRUCKS\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"UNIT #\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 92,\n        \"samples\": [\n          \"ST04\",\n          \"GB2\",\n          \"BD2\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"SSOL ELBAYAP\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"SSOL ELBAYAP\",\n          \"Covered\",\n          \"\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"YEAR\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 31,\n        \"samples\": [\n          \"1992\",\n          \"2005\",\n          \"1980\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"MAKE/MODEL\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 99,\n        \"samples\": [\n          \"Doepker HHT/RL 50 Tn Tridem\\nScissorneck Lowboy\",\n          \"Chevrolet Silverado 3500\",\n          \"Trailtech H370-22 B.P.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"SERIAL NUMBER\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 114,\n        \"samples\": [\n          \"2C94425E3E1086562\",\n          \"1FVHALAV37DY44777\",\n          \"1FT7W2B69KEE30111\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"VALUE\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 34,\n        \"samples\": [\n          \"$50,000\",\n          \"$37,000\",\n          \"$52,000\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"SECTION A\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 7,\n        \"samples\": [\n          \"$5,000,000\",\n          \"LIABILITY LIMIT\",\n          \"Not Covered\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"SECTION A.1\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"\",\n          \"SP\",\n          \"DCPD DEDUCTIBLE\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"SECTION B\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 7,\n        \"samples\": [\n          \"ACCIDENT BENEFITS\",\n          \"Covered\",\n          \"N/A\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"SECTION C - PHYSICAL DAMAGE\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 7,\n        \"samples\": [\n          \"ALL PERILS\\nDEDUCTIBLE\",\n          \"$5,000\",\n          \"$10,000\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": null,\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"\",\n          \"COLLISION\\nDEDUCTIBLE\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": null,\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"\",\n          \"COMP.\\nDEDUCTIBLE\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": null,\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"\",\n          \"SPEC. PERILS\\nDEDUCTIBLE\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ENDORSEMENTS\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 8,\n        \"samples\": [\n          \"\",\n          \"20, 21B, 23A, 27,\\n30, 30A, 40, 44\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ADD/\\nDELETE\\nDATE\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"ADD/\\nDELETE\\nDATE\",\n          \"\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "G2sCtejSN_XN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the Excel file\n",
        "file_path = '/content/sample_data.xlsx'\n",
        "xls = pd.ExcelFile(file_path)\n",
        "\n",
        "# Load both sheets\n",
        "sheet1 = pd.read_excel(xls, 'Sheet1', skiprows=3)\n",
        "# sheet2 = pd.read_excel(xls, 'Sheet2')\n",
        "\n",
        "# Drop any completely empty columns\n",
        "sheet1.dropna(how='all', axis=1, inplace=True)\n",
        "\n",
        "# Check the number of columns before renaming\n",
        "print(\"Number of columns:\", len(sheet1.columns))\n",
        "\n",
        "\n",
        "# Rename the columns to match Sheet 2\n",
        "# sheet1.columns = ['# UNIT #', 'SSOL ELBAYAP', 'YEAR', 'MAKE/MODEL', 'SERIAL NUMBER', 'VALUE', 'SECTION A', 'SECTION A.1', 'SECTION B', 'SECTION C - PHYSICAL DAMAGE', 'Unnamed: 11', 'Unnamed: 12', 'Unnamed: 13', 'ENDORSEMENTS', 'ADD/\\nDELETE\\nDATE']\n",
        "\n",
        "\n",
        "\n",
        "# Rename the columns\n",
        "new_column_names = {\n",
        "    '# UNIT #': 'Unit Number',\n",
        "\n",
        "    'YEAR': 'Year',\n",
        "    'MAKE/MODEL': 'Make/Model',\n",
        "    'SERIAL NUMBER': 'Serial Number',\n",
        "    'VALUE': 'Value',\n",
        "    'SECTION A': 'Section A',\n",
        "    'SECTION A.1': 'TPL',\n",
        "    'SECTION B': 'Section B',\n",
        "    'SECTION C - PHYSICAL DAMAGE': 'ALL Perils','ENDORSEMENTS': 'Endorsements',\n",
        "\n",
        "}\n",
        "sheet1.rename(columns=new_column_names, inplace=True)\n",
        "\n",
        "\n",
        "# Drop any rows that are completely empty\n",
        "sheet1.dropna(how='all', inplace=True)\n",
        "\n",
        "# Display the cleaned data\n",
        "sheet1_cleaned = sheet1.reset_index(drop=True)\n",
        "sheet1_cleaned.head()\n",
        "\n",
        "# Convert the cleaned data into a DataFrame\n",
        "selected_df = pd.DataFrame(sheet1_cleaned)\n",
        "\n",
        "# Print the DataFrame to verify\n",
        "print(selected_df.head())\n",
        "\n",
        "\n",
        "# # Save the cleaned data to a new Excel file\n",
        "# output_path = '/mnt/data/cleaned_data.xlsx'\n",
        "# with pd.ExcelWriter(output_path) as writer:\n",
        "#     sheet1_cleaned.to_excel(writer, index=False, sheet_name='Sheet1')\n",
        "#     sheet2.to_excel(writer, index=False, sheet_name='Sheet2')\n",
        "\n",
        "# output_path\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sOKDeQBiN_Ul",
        "outputId": "ced7db91-b74c-499f-94a6-61d71e345cfe"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of columns: 16\n",
            "  HEAVY COMMERCIAL - DUMP TRUCKS Unnamed: 1 Unnamed: 2 Unnamed: 3  \\\n",
            "0                              1        FL1        NaN       2004   \n",
            "1                              2        FL2        NaN       2006   \n",
            "2                              3        FL3        NaN       2006   \n",
            "3                              4        FL4        NaN       2012   \n",
            "4                              5        FL5        NaN       2007   \n",
            "\n",
            "                         Unnamed: 4         Unnamed: 5 Unnamed: 6 Unnamed: 7  \\\n",
            "0    Freightliner FLD120SD T/A Dump  1FVHALAV04DN28068    $75,000    Covered   \n",
            "1           Freightliner Dump Truck  1FVHALAV56DW57006    $75,000    Covered   \n",
            "2    Freightliner FLD120SD T/A Dump  1FVHALAV66DW57001    $75,000    Covered   \n",
            "3  Freightliner Coronada 122SD Dump  1FVHGNDR8CDBN6604    $85,000    Covered   \n",
            "4    Freightliner FLD120SD T/A Dump  1FVHALAV37DY44777    $65,000    Covered   \n",
            "\n",
            "  Unnamed: 8 Unnamed: 9 Unnamed: 10 Unnamed: 11 Unnamed: 12 Unnamed: 13  \\\n",
            "0        NaN    Covered      $5,000         NaN         NaN         NaN   \n",
            "1        NaN    Covered      $5,000         NaN         NaN         NaN   \n",
            "2        NaN    Covered      $5,000         NaN         NaN         NaN   \n",
            "3        NaN    Covered      $5,000         NaN         NaN         NaN   \n",
            "4        NaN    Covered      $5,000         NaN         NaN         NaN   \n",
            "\n",
            "                  Unnamed: 14 Unnamed: 15  \n",
            "0  21B, 23A, 30, 30A,\\n40, 44         NaN  \n",
            "1  21B, 23A, 30, 30A,\\n40, 44         NaN  \n",
            "2  21B, 23A, 30, 30A,\\n40, 44         NaN  \n",
            "3  21B, 23A, 30, 30A,\\n40, 44         NaN  \n",
            "4  21B, 23A, 30, 30A,\\n40, 44         NaN  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GA7ioK15QWV9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the Excel file\n",
        "file_path = '/content/sample_data.xlsx'\n",
        "xls = pd.ExcelFile(file_path)\n",
        "\n",
        "# Reload Sheet 1 with the correct header row\n",
        "sheet1 = pd.read_excel(xls, 'Sheet1', skiprows=2)\n",
        "\n",
        "# Drop any completely empty columns\n",
        "sheet1.dropna(how='all', axis=1, inplace=True)\n",
        "\n",
        "# Rename the columns\n",
        "new_column_names = {\n",
        "    '# UNIT #': 'Unit Number',\n",
        "\n",
        "    'YEAR': 'Year',\n",
        "    'MAKE/MODEL': 'Make/Model',\n",
        "    'SERIAL NUMBER': 'Serial Number',\n",
        "    'VALUE': 'Value',\n",
        "    'SECTION A': 'Section A',\n",
        "    'SECTION A.1': 'TPL',\n",
        "    'SECTION B': 'Section B',\n",
        "    'SECTION C - PHYSICAL DAMAGE': 'ALL Perils','ENDORSEMENTS': 'Endorsements',\n",
        "\n",
        "}\n",
        "sheet1.rename(columns=new_column_names, inplace=True)\n",
        "\n",
        "# Drop any rows that are completely empty\n",
        "sheet1.dropna(how='all', inplace=True)\n",
        "\n",
        "# Reset index\n",
        "sheet1_cleaned = sheet1.reset_index(drop=True)\n",
        "\n",
        "# # Save the cleaned data to a new Excel file\n",
        "# output_path = 'path_to_your_file/cleaned_data.xlsx'\n",
        "# with pd.ExcelWriter(output_path) as writer:\n",
        "#     sheet1_cleaned.to_excel(writer, index=False, sheet_name='Sheet1')\n",
        "#     sheet2.to_excel(writer, index=False, sheet_name='Sheet2')\n",
        "\n",
        "# print(\"Cleaned data has been saved to:\", output_path)\n"
      ],
      "metadata": {
        "id": "tAxsQ5P6QWTE"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the cleaned data into a DataFrame\n",
        "cleaned_df = pd.DataFrame(sheet1_cleaned)\n",
        "\n",
        "# Print the DataFrame to verify\n",
        "print(cleaned_df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BPXZhdHnQWQo",
        "outputId": "ebcbd179-3688-4830-a540-218e7d586cc8"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                       Unnamed: 0 Unnamed: 1 Unnamed: 2 Unnamed: 3  \\\n",
            "0  HEAVY COMMERCIAL - DUMP TRUCKS        NaN        NaN        NaN   \n",
            "1                               1        FL1        NaN       2004   \n",
            "2                               2        FL2        NaN       2006   \n",
            "3                               3        FL3        NaN       2006   \n",
            "4                               4        FL4        NaN       2012   \n",
            "\n",
            "                         Unnamed: 4         Unnamed: 5 Unnamed: 6  \\\n",
            "0                               NaN                NaN        NaN   \n",
            "1    Freightliner FLD120SD T/A Dump  1FVHALAV04DN28068    $75,000   \n",
            "2           Freightliner Dump Truck  1FVHALAV56DW57006    $75,000   \n",
            "3    Freightliner FLD120SD T/A Dump  1FVHALAV66DW57001    $75,000   \n",
            "4  Freightliner Coronada 122SD Dump  1FVHGNDR8CDBN6604    $85,000   \n",
            "\n",
            "  LIABILITY LIMIT Unnamed: 8 Unnamed: 9 Unnamed: 10 Unnamed: 11 Unnamed: 12  \\\n",
            "0             NaN        NaN        NaN         NaN         NaN         NaN   \n",
            "1         Covered        NaN    Covered      $5,000         NaN         NaN   \n",
            "2         Covered        NaN    Covered      $5,000         NaN         NaN   \n",
            "3         Covered        NaN    Covered      $5,000         NaN         NaN   \n",
            "4         Covered        NaN    Covered      $5,000         NaN         NaN   \n",
            "\n",
            "  Unnamed: 13                 Unnamed: 14 Unnamed: 15  \n",
            "0         NaN                         NaN         NaN  \n",
            "1         NaN  21B, 23A, 30, 30A,\\n40, 44         NaN  \n",
            "2         NaN  21B, 23A, 30, 30A,\\n40, 44         NaN  \n",
            "3         NaN  21B, 23A, 30, 30A,\\n40, 44         NaN  \n",
            "4         NaN  21B, 23A, 30, 30A,\\n40, 44         NaN  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Gw_9VDMqQWOM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KPeXS8bSQWLt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "R9JOYxPVQWI0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wU9vNGTgQWF9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WCZ8ncaGN_SN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X=np.array(sheet1_cleaned['YEAR\t', 'SERIAL NUMBER', 'VALUE','SECTION A','SECTION C - PHYSICAL DAMAGE', '']).reshape((-1, 1))\n",
        "y=np.array(sheet1_cleaned['Temperature (C)'])\n",
        "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3,random_state=200)"
      ],
      "metadata": {
        "id": "cGLv8rXdPpjM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RMYhH3YXPpf-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bbmO5pFxPpc8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gXm86QsNPpaO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8JxJPtXkPpXX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5MgYq693PpU7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9q0vB5y3PpSE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "C6cGXgXXPpPD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1-M2ye1QPpMc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pJrc-3f0PpJb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JHGe34AqPpG0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "u8ZiMmIdPpD7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZNGxT627PpBP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ihYc_Y7IPo-L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GbBF4brCN_Pm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MZ4RimVGN_M1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oNfm5BlWN_Kd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hxcDq50iN_Hs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zrl0JfnkN_FN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "v2vIbSVTN_CV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "y-VclDKwN-_N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Z3C4sKkrN-t3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import pandas as pd\n",
        "\n",
        "# # Assuming 'df' is your DataFrame from the previous code\n",
        "\n",
        "# def clean_dataframe(df, none_threshold=0.5):\n",
        "#     # Remove rows where all values are None\n",
        "#     df_cleaned = df.dropna(how='all')\n",
        "\n",
        "#     # Remove rows that contain specific unwanted text (e.g., headers and footers)\n",
        "#     unwanted_texts = [\n",
        "#         \"# UNIT # SSOL ELBAYAP YEAR MAKE/MODEL SERIAL NUMBER VALUE SECTION A SECTION A.1 SECTION B SECTION C - PHYSICAL DAMAGE None None None ENDORSEMENTS ADD/DELETE DATE\",\n",
        "#         \"LIABILITY LIMIT\",\n",
        "#         \"This schedule is issued for information purpos...\",\n",
        "#         \"Please Sign and Return\"\n",
        "#     ]\n",
        "\n",
        "#     for text in unwanted_texts:\n",
        "#         df_cleaned = df_cleaned[~df_cleaned.apply(lambda row: row.astype(str).str.contains(text).any(), axis=1)]\n",
        "\n",
        "#           # Remove rows with a high number of None values\n",
        "#     max_none_count = int(len(df_cleaned.columns) * none_threshold)\n",
        "#     df_cleaned = df_cleaned[df_cleaned.isnull().sum(axis=1) <= max_none_count]\n",
        "\n",
        "#     # Optionally, reset the index if needed\n",
        "#     df_cleaned.reset_index(drop=True, inplace=True)\n",
        "\n",
        "#     return df_cleaned\n",
        "\n",
        "#     # Optionally, reset the index if needed\n",
        "#     df_cleaned.reset_index(drop=True, inplace=True)\n",
        "\n",
        "#     return df_cleaned\n",
        "\n",
        "# # Example usage\n",
        "# if __name__ == \"__main__\":\n",
        "#     # Clean the DataFrame\n",
        "#     df_cleaned = clean_dataframe(df)\n",
        "\n",
        "#     # Print cleaned DataFrame\n",
        "#     print(\"Cleaned DataFrame:\")\n",
        "#     print(df_cleaned)\n"
      ],
      "metadata": {
        "id": "CH7JKHxVeVpP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_cleaned"
      ],
      "metadata": {
        "id": "6OJK7E1leVmX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Calculate the accuracy and get insights\n",
        "# print(\"Summary statistics:\")\n",
        "# print(df_cleaned.describe(include='all'))\n",
        "\n",
        "# # Check for missing values\n",
        "# print(\"Missing values per column:\")\n",
        "# print(df_cleaned.isnull().sum())\n",
        "\n",
        "# # Additional insights\n",
        "# # Example: Value counts for categorical columns\n",
        "# print(\"Value counts for categorical columns:\")\n",
        "# # Filter out columns named 'None' to avoid the error\n",
        "# for col in df_cleaned.select_dtypes(include=['object']).columns:\n",
        "#     if col is not None:  # Check if the column name is not None\n",
        "#         print(f\"{col}:\\n{df_cleaned[col].value_counts()}\\n\")"
      ],
      "metadata": {
        "id": "TGj3W87M7lKS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Calculate the accuracy and get insights\n",
        "# print(\"Summary statistics:\")\n",
        "# print(df_cleaned.describe(include='all'))\n",
        "\n",
        "# # Check for missing values\n",
        "# print(\"Missing values per column:\")\n",
        "# print(df_cleaned.isnull().sum())\n",
        "\n",
        "# # Additional insights\n",
        "# # Example: Value counts for categorical columns\n",
        "# print(\"Value counts for categorical columns:\")\n",
        "# # Get a list of column names EXCLUDING those with the name None\n",
        "# valid_columns = [col for col in df_cleaned.select_dtypes(include=['object']).columns if col is not None]\n",
        "# for col in valid_columns:\n",
        "#     print(f\"{col}:\\n{df_cleaned[col].value_counts()}\\n\")"
      ],
      "metadata": {
        "id": "S-Vhkwdck405"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "ekgM8BtYJOnC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the target variable\n",
        "target_variable = 'TARGET_VARIABLE'\n",
        "\n",
        "# Define the feature columns (excluding the target variable)\n",
        "feature_columns = [col for col in df.columns if col != target_variable]\n",
        "\n",
        "# Display the feature columns\n",
        "print(\"Feature Columns:\")\n",
        "print(feature_columns)\n",
        "\n",
        "# Display the target variable\n",
        "print(\"\\nTarget Variable:\")\n",
        "print(target_variable)"
      ],
      "metadata": {
        "id": "o5GIz0qpmCYG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Value counts for 'YEAR':\")\n",
        "print(df['YEAR'].value_counts())"
      ],
      "metadata": {
        "id": "xRx2wS9b_j45"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_cleaned.head()"
      ],
      "metadata": {
        "id": "yrLYBKdP_eM4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_cleaned"
      ],
      "metadata": {
        "id": "4dHxVRL7CMX-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(list(df.columns))\n",
        "for column in df.columns:\n",
        "    print(column)"
      ],
      "metadata": {
        "id": "BFLDFn1TmCaf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_filtered."
      ],
      "metadata": {
        "id": "e57Zg6oAFx2s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Selecting specific columns\n",
        "new_auto = ['YEAR', 'MAKE/MODEL', 'SERIAL NUMBER', 'VALUE', 'ENDORSEMENTS', 'SECTION A', 'SECTION A.1', 'SECTION B']\n",
        "\n",
        "# Create a new DataFrame with selected columns\n",
        "df_filtered = df_cleaned[new_auto]\n",
        "\n",
        "# Display the filtered DataFrame\n",
        "print(df_filtered)"
      ],
      "metadata": {
        "id": "uaDk6ugjDm0F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Example: Logistic Regression for classification\n",
        "\n",
        "# Prepare the data (this will depend on your specific dataset)\n",
        "# Check the actual column names in your DataFrame\n",
        "print(df_filtered.columns)\n",
        "\n",
        "# Use the target_variable to select the correct column name\n",
        "X = df_filtered.drop(target_variable, axis=1)  # Features\n",
        "y = df_filtered[target_variable]  # Target variable\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train the model\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "id": "lwW-20FW-K-H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Example: Logistic Regression for classification\n",
        "\n",
        "# Prepare the data (this will depend on your specific dataset)\n",
        "# Check the actual column names in your DataFrame\n",
        "print(df_cleaned.columns)\n",
        "\n",
        "# Assume 'TARGET_VARIABLE' is the actual name of the column you want to predict\n",
        "X = df_cleaned.drop('target_variable', axis=1)  # Features\n",
        "y = df_cleaned['target_variable']  # Target variable\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train the model\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "id": "_suxwCMuk4vI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wSs3YRR4k4ma"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Example: Logistic Regression for classification\n",
        "\n",
        "# Prepare the data (this will depend on your specific dataset)\n",
        "# Assume 'target' is the column you want to predict\n",
        "X = df_cleaned.drop('target', axis=1)  # Features\n",
        "y = df_cleaned['target']  # Target variable\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train the model\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "id": "8iT_HBXShzBb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ltVK6pWEk94K"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}